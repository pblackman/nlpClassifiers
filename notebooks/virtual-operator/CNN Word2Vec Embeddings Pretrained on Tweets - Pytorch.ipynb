{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os.path import join\n",
    "import os\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from torch.nn.init import kaiming_uniform_\n",
    "from torch.optim import SGD\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from torch.optim import Adam\n",
    "from nlpClassifiers.data.dataset  import NLPDataset, Vocabulary\n",
    "from sklearn.metrics import roc_curve, auc, classification_report\n",
    "from scipy.special import expit\n",
    "import gensim\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '../../'\n",
    "PATH_TO_VIRTUAL_OPERATOR_DATA = join(ROOT, \"data/virtual-operator\")\n",
    "PATH_TO_AGENT_BENCHMARK_DATA = join(ROOT, \"data/agent-benchmark\")\n",
    "PATH_TO_ML_PT_DATA = join(ROOT, \"data/mercado-livre-pt-only\")\n",
    "\n",
    "PATH_TO_VIRTUAL_OPERATOR_MODELS = join(ROOT, \"models/virtual-operator\")\n",
    "PATH_TO_AGENT_BENCHMARK_MODELS = join(ROOT, \"models/agent-benchmark\")\n",
    "PATH_TO_ML_PT_MODELS = join(ROOT, \"models/mercado-livre-pt-only\")\n",
    "\n",
    "EMBEDDING_DIM = 300\n",
    "EMBEDDINGS_FILE = '../../data/twitter-pt/vocab/word2vec-model-tweets-pmann-reduced-pt.bin'\n",
    "MAX_WORDS = 30000\n",
    "dataset = 'virtual-operator'\n",
    "sentence_max_len = 82\n",
    "batch_size = 512\n",
    "\n",
    "epochs=30\n",
    "stopwords_lang = None\n",
    "gpu=1\n",
    "lr=0.001\n",
    "clipping_value=0.25\n",
    "save_name='cnn-pytorch-word2vec-tweets-embeddings'\n",
    "patience=5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_TO_MODELS = {\"virtual-operator\": PATH_TO_VIRTUAL_OPERATOR_MODELS, \"agent-benchmark\": PATH_TO_AGENT_BENCHMARK_MODELS, \"mercado-livre-pt\": PATH_TO_ML_PT_MODELS}\n",
    "FULL_PATH_TO_MODELS = join(BASE_PATH_TO_MODELS[dataset], \"bow-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _init_fn(worker_id):\n",
    "    np.random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(dataset, subset):\n",
    "    BASE_PATH_TO_DATASET = {\"virtual-operator\": PATH_TO_VIRTUAL_OPERATOR_DATA, \"agent-benchmark\": PATH_TO_AGENT_BENCHMARK_DATA, \"mercado-livre-pt\": PATH_TO_ML_PT_DATA}\n",
    "    BASE_PATH_TO_DATASET = {\"train\": join(BASE_PATH_TO_DATASET[dataset], \"train.csv\"), \"val\": join(BASE_PATH_TO_DATASET[dataset], \"val.csv\"), \"test\": join(BASE_PATH_TO_DATASET[dataset], \"test.csv\")}\n",
    "    FULL_PATH_TO_DATASET = BASE_PATH_TO_DATASET[subset]\n",
    "    \n",
    "    if dataset == \"mercado-livre-pt\":\n",
    "        sep=\",\"\n",
    "    else:\n",
    "        sep=\";\"\n",
    "    data = pd.read_csv(FULL_PATH_TO_DATASET, sep=sep, names =['utterance','label'], header=None, dtype={'utterance':str, 'label': str} )\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = read_data(dataset, \"train\")\n",
    "val_df = read_data(dataset, \"val\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5655 tokens not found in vocabulary.\n"
     ]
    }
   ],
   "source": [
    "voc = Vocabulary('CNN', stopwords_lang)\n",
    "voc.build_vocab(train_df['utterance'].tolist() +  val_df['utterance'].tolist(), MAX_WORDS)\n",
    "embedding_weights = voc.load_embeddings(EMBEDDINGS_FILE, EMBEDDING_DIM)\n",
    "if voc.num_words < MAX_WORDS or MAX_WORDS == 0:\n",
    "    MAX_WORDS = voc.num_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = NLPDataset(dataset, \"train\", sentence_max_len, vocab= voc)\n",
    "labels_dict = train_corpus.labels_dict\n",
    "val_corpus = NLPDataset(dataset, \"val\", sentence_max_len, labels_dict = labels_dict, vocab= voc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(\n",
    "            train_corpus,\n",
    "            sampler = RandomSampler(train_corpus),\n",
    "            batch_size = batch_size,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=_init_fn,\n",
    "            num_workers=0\n",
    ")\n",
    "\n",
    "validation_dataloader = DataLoader(\n",
    "            val_corpus,\n",
    "            sampler = RandomSampler(val_corpus),\n",
    "            batch_size = batch_size,\n",
    "            pin_memory=True,\n",
    "            worker_init_fn=_init_fn,\n",
    "            num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize_weights(model):\n",
    "    if type(model) in [nn.Linear]:\n",
    "        nn.init.xavier_normal_(model.weight.data)\n",
    "    elif type(model) in [nn.LSTM, nn.RNN, nn.GRU]:\n",
    "        nn.init.xavier_normal_(model.weight_hh_l0)\n",
    "        nn.init.xavier_normal_(model.weight_ih_l0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNNNet(nn.Module):\n",
    "    def __init__(self, num_classes, num_features, criterion, embedding_dim, embedding_weights=None):\n",
    "        super(CNNNet, self).__init__()\n",
    "        self.criterion = criterion\n",
    "        self.embedding_dim = embedding_dim\n",
    "        self.n_layers = 1\n",
    "        self.embedding = nn.Embedding(num_features, embedding_dim, padding_idx = 0)\n",
    "        if(embedding_weights is not None):\n",
    "            print(\"Embedding layer Weights won't be updated.\")\n",
    "            self.embedding.load_state_dict({'weight': embedding_weights})\n",
    "            self.embedding.weight.requires_grad = False\n",
    "            #self.embedding.from_pretrained(embedding_weights, freeze=True)\n",
    "        else:\n",
    "            self.embedding.weight.data = torch.zeros(self.embedding.weight.data.size())\n",
    "            self.embedding.weight.requires_grad = True\n",
    "        \n",
    "        self.cnn = nn.Conv1d(embedding_dim, 256, 4)\n",
    "        \n",
    "        for name, param in self.cnn.named_parameters():\n",
    "            if 'bias' in name:\n",
    "                nn.init.constant_(param, 0.0)\n",
    "            elif 'weight_ih' in name:\n",
    "                nn.init.kaiming_normal_(param)\n",
    "            elif 'weight_hh' in name:\n",
    "                nn.init.orthogonal_(param)\n",
    "             \n",
    "        self.dropout = nn.Dropout(0.2)       \n",
    "        self.out = nn.Linear(256, num_classes)\n",
    "        self.init_weights()\n",
    "    def forward(self, x, y):\n",
    "        # Conv1d takes in (batch, channels, seq_len), but raw embedded is (batch, seq_len, channels)\n",
    "        h_embedding = self.embedding(x)\n",
    "        h_embedding = h_embedding.permute(0, 2, 1)\n",
    "        h_cnn = self.cnn(h_embedding)\n",
    "        h_cnn = h_cnn.permute(0, 2, 1)\n",
    "        h_cnn = self.dropout(h_cnn)\n",
    "        h_max_pool = self.global_max_pool(h_cnn)\n",
    "        x = self.out(h_max_pool)\n",
    "        loss = self.criterion(x, y)\n",
    "        # return the final output\n",
    "        return loss,x \n",
    "    \n",
    "    @staticmethod\n",
    "    def global_max_pool(x):\n",
    "        \"\"\"Convolution and global max pooling layer\"\"\"\n",
    "        return x.max(1)[0]\n",
    "    \n",
    "    def init_weights(self):\n",
    "        \"\"\"\n",
    "        Here we reproduce Keras default initialization weights to initialize Embeddings/LSTM weights\n",
    "        \"\"\"\n",
    "        ih = (param.data for name, param in self.named_parameters() if 'weight_ih' in name)\n",
    "        hh = (param.data for name, param in self.named_parameters() if 'weight_hh' in name)\n",
    "        b = (param.data for name, param in self.named_parameters() if 'bias' in name)\n",
    "        for t in ih:\n",
    "            nn.init.xavier_uniform(t)\n",
    "        for t in hh:\n",
    "            nn.init.orthogonal(t)\n",
    "        for t in b:\n",
    "            nn.init.constant(t, 0)\n",
    "    \n",
    "    def init_hidden(self, batch_size, device):\n",
    "        weight = next(self.parameters()).data\n",
    "        hidden = (weight.new(self.n_layers, batch_size, self.embedding_dim).zero_().to(device),\n",
    "                      weight.new(self.n_layers, batch_size, self.embedding_dim).zero_().to(device))\n",
    "        return hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding layer Weights won't be updated.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:60: UserWarning: nn.init.constant is now deprecated in favor of nn.init.constant_.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "model = CNNNet(train_corpus.num_labels, MAX_WORDS, criterion, EMBEDDING_DIM, embedding_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CNNNet(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (embedding): Embedding(22418, 300, padding_idx=0)\n",
       "  (cnn): Conv1d(300, 256, kernel_size=(4,), stride=(1,))\n",
       "  (dropout): Dropout(p=0.2, inplace=False)\n",
       "  (out): Linear(in_features=256, out_features=121, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.apply(initialize_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{gpu}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = model.to(device)\n",
    "optimizer = Adam(model.parameters(),lr, betas=(0.7, 0.999))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def multi_acc(y_pred, y_test):\n",
    "    y_pred_softmax = torch.log_softmax(y_pred, dim = 1)\n",
    "    _, y_pred_tags = torch.max(y_pred_softmax, dim = 1)    \n",
    "    \n",
    "    correct_pred = (y_pred_tags == y_test).float()\n",
    "    acc = correct_pred.sum() / len(correct_pred)\n",
    "    acc = acc * 100.0\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    acc = (labels.cpu() == logits.cpu().argmax(-1)).float().detach().numpy()\n",
    "    return float(100 * acc.sum() / len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======== Epoch 1 / 30 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:25: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    943.    .\n",
      "  step loss: 1.25\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 1.12\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 1.08\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.96\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.98\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 1.01\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.87\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.92\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.72\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.83\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.71\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.74\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.68\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.72\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.74\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.84\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.61\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.66\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.63\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.70\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.71\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.74\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.66\n",
      "\n",
      "  Average training loss: 0.86\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 83.40\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:53: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 82.23\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 82.23\n",
      "Batch accuracy: 83.01\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 83.01\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 80.66\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 81.64\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 81.45\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 83.98\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 83.01\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 82.42\n",
      "Batch accuracy: 82.62\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 82.42\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 80.27\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 82.81\n",
      "Batch accuracy: 82.42\n",
      "Batch accuracy: 83.01\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 82.23\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 82.23\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 83.20\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 82.81\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 82.81\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 83.98\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 82.62\n",
      "Batch accuracy: 80.86\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 83.20\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 82.81\n",
      "Batch accuracy: 83.59\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 81.84\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 81.84\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 83.20\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 82.81\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 83.59\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 82.23\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 83.01\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 85.59\n",
      "  Accuracy: 84.30\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 2 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.59\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.58\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.60\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.59\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.68\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.66\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.65\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.63\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.56\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.57\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.58\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.56\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.65\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.65\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.59\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.65\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.67\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.59\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.49\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.51\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.52\n",
      "\n",
      "  Average training loss: 0.60\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 83.40\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 82.62\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 83.59\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 83.59\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 83.98\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 83.98\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 83.01\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 82.03\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 82.81\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 83.20\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 82.42\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.76\n",
      "  Accuracy: 85.86\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 3 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.59\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.51\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.56\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.55\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.56\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.60\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.65\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.53\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.60\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.57\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.55\n",
      "\n",
      "  Average training loss: 0.52\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 83.98\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.11\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 84.18\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 87.03\n",
      "  Accuracy: 86.75\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 4 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.53\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.51\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.39\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.56\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.51\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.58\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.53\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.53\n",
      "\n",
      "  Average training loss: 0.48\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 87.03\n",
      "  Accuracy: 87.33\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 5 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.49\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.39\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.47\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.51\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.43\n",
      "\n",
      "  Average training loss: 0.45\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 83.79\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 85.16\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 84.38\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.17\n",
      "  Accuracy: 87.66\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 6 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.44\n",
      "\n",
      "  Average training loss: 0.42\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 85.59\n",
      "  Accuracy: 88.42\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 7 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.50\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.52\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.49\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.53\n",
      "\n",
      "  Average training loss: 0.40\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 85.35\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 84.77\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 84.57\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 84.96\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 86.46\n",
      "  Accuracy: 88.03\n",
      "The model does not improve for 1 epochs!\n",
      "\n",
      "======== Epoch 8 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.31\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.49\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.46\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.39\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.46\n",
      "\n",
      "  Average training loss: 0.39\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 88.47\n",
      "  Accuracy: 88.95\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 9 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.39\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.48\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.43\n",
      "\n",
      "  Average training loss: 0.37\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 93.36\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 85.94\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.32\n",
      "  Accuracy: 89.03\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 10 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.30\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.54\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.30\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.45\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.45\n",
      "\n",
      "  Average training loss: 0.36\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.89\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.63\n",
      "  Accuracy: 89.16\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 11 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.44\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.30\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.33\n",
      "\n",
      "  Average training loss: 0.35\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.63\n",
      "  Accuracy: 89.10\n",
      "The model does not improve for 1 epochs!\n",
      "\n",
      "======== Epoch 12 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.39\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.30\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.43\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.31\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.38\n",
      "\n",
      "  Average training loss: 0.34\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 86.33\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.67\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.11\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 85.55\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 86.52\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.49\n",
      "  Accuracy: 89.20\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 13 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.30\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.36\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.40\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.42\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.34\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.37\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.41\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.38\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.27\n",
      "\n",
      "  Average training loss: 0.33\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 86.72\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 85.74\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 87.32\n",
      "  Accuracy: 89.08\n",
      "The model does not improve for 1 epochs!\n",
      "Epoch    13: reducing learning rate of group 0 to 1.0000e-04.\n",
      "\n",
      "======== Epoch 14 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.35\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.30\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.33\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.32\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.27\n",
      "\n",
      "  Average training loss: 0.25\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 93.75\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.34\n",
      "  Accuracy: 90.37\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 15 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.24\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.19\n",
      "\n",
      "  Average training loss: 0.23\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 93.16\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 94.14\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 93.16\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.63\n",
      "  Accuracy: 90.44\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 16 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.23\n",
      "\n",
      "  Average training loss: 0.22\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 93.55\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.20\n",
      "  Accuracy: 90.50\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 17 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.14\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.14\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.26\n",
      "\n",
      "  Average training loss: 0.21\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 91.07\n",
      "  Accuracy: 90.58\n",
      "New best model, saving it!\n",
      "\n",
      "======== Epoch 18 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.22\n",
      "\n",
      "  Average training loss: 0.21\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.34\n",
      "  Accuracy: 90.55\n",
      "The model does not improve for 1 epochs!\n",
      "\n",
      "======== Epoch 19 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.27\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.26\n",
      "\n",
      "  Average training loss: 0.20\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 93.75\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.84\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 93.16\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.78\n",
      "  Accuracy: 90.51\n",
      "The model does not improve for 2 epochs!\n",
      "\n",
      "======== Epoch 20 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.11\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.29\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.19\n",
      "\n",
      "  Average training loss: 0.20\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 93.36\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 93.16\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.49\n",
      "  Accuracy: 90.55\n",
      "The model does not improve for 3 epochs!\n",
      "\n",
      "======== Epoch 21 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.26\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.25\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.14\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.12\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.18\n",
      "\n",
      "  Average training loss: 0.20\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 94.14\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 93.16\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 86.91\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.35\n",
      "  Accuracy: 90.53\n",
      "The model does not improve for 4 epochs!\n",
      "Epoch    21: reducing learning rate of group 0 to 1.0000e-05.\n",
      "\n",
      "======== Epoch 22 / 30 ========\n",
      "Training...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.13\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.14\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.22\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.20\n",
      "\n",
      "  Average training loss: 0.19\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 86.13\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.26\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 87.50\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 87.70\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 93.55\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.63\n",
      "  Accuracy: 90.52\n",
      "The model does not improve for 5 epochs!\n",
      "\n",
      "======== Epoch 23 / 30 ========\n",
      "Training...\n",
      "  Batch    40  of    943.    .\n",
      "  step loss: 0.19\n",
      "  Batch    80  of    943.    .\n",
      "  step loss: 0.28\n",
      "  Batch   120  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   160  of    943.    .\n",
      "  step loss: 0.16\n",
      "  Batch   200  of    943.    .\n",
      "  step loss: 0.12\n",
      "  Batch   240  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   280  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   320  of    943.    .\n",
      "  step loss: 0.15\n",
      "  Batch   360  of    943.    .\n",
      "  step loss: 0.23\n",
      "  Batch   400  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   440  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   480  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   520  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   560  of    943.    .\n",
      "  step loss: 0.18\n",
      "  Batch   600  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   640  of    943.    .\n",
      "  step loss: 0.24\n",
      "  Batch   680  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   720  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   760  of    943.    .\n",
      "  step loss: 0.21\n",
      "  Batch   800  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   840  of    943.    .\n",
      "  step loss: 0.17\n",
      "  Batch   880  of    943.    .\n",
      "  step loss: 0.20\n",
      "  Batch   920  of    943.    .\n",
      "  step loss: 0.18\n",
      "\n",
      "  Average training loss: 0.19\n",
      "\n",
      "Running Validation...\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.58\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 92.19\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.28\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 92.97\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 88.48\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 92.77\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 89.45\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 87.30\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 89.65\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.23\n",
      "Batch accuracy: 89.84\n",
      "Batch accuracy: 88.09\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.21\n",
      "Batch accuracy: 91.99\n",
      "Batch accuracy: 90.43\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.62\n",
      "Batch accuracy: 93.36\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 91.80\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 93.16\n",
      "Batch accuracy: 88.87\n",
      "Batch accuracy: 88.67\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.60\n",
      "Batch accuracy: 91.02\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 92.38\n",
      "Batch accuracy: 91.41\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 87.89\n",
      "Batch accuracy: 89.06\n",
      "Batch accuracy: 90.04\n",
      "Batch accuracy: 90.82\n",
      "Batch accuracy: 90.20\n",
      "  Accuracy: 90.55\n",
      "The model does not improve for 6 epochs!\n",
      "====>Stopping training, the model did not improve for 6\n",
      "====>Best epoch: 17.\n",
      "\n",
      "Training complete!\n"
     ]
    }
   ],
   "source": [
    "scheduler = ReduceLROnPlateau(optimizer, mode='min', patience=3,verbose=True, factor=0.1)\n",
    "\n",
    "best_epoch = -1\n",
    "last_saved_model = \"\"\n",
    "training_stats = []\n",
    "global_step = 0\n",
    "best_val_acc = float(\"-inf\")\n",
    "best_model_wts = None\n",
    "best_curr_val = 0\n",
    "\n",
    "for epoch_i in range(0, epochs):\n",
    "    print(\"\")\n",
    "    print('======== Epoch {:} / {:} ========'.format(epoch_i + 1, epochs))\n",
    "    print('Training...')\n",
    "    total_train_loss = 0\n",
    "    model.train()\n",
    "    for step, batch in enumerate(train_dataloader):\n",
    "        #val_h = model.init_hidden(len(batch[0]), device)\n",
    "        #val_h = tuple([each.data for each in val_h])\n",
    "         # Progress update every 40 batches.\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            print('  Batch {:>5,}  of  {:>5,}.    .'.format(step, len(train_dataloader)))\n",
    "        b_input_ids = batch[0]\n",
    "        b_labels = batch[1].to(device)\n",
    "        b_input_ids = torch.tensor(b_input_ids).to(device).long()\n",
    "        model.zero_grad()\n",
    "        loss, logits = model(b_input_ids, b_labels)\n",
    "        loss.backward()\n",
    "        torch.nn.utils.clip_grad_norm_(model.parameters(), clipping_value)\n",
    "        optimizer.step()\n",
    "        step_loss = loss.item()\n",
    "        if step % 40 == 0 and not step == 0:\n",
    "            print(\"  step loss: {0:.2f}\".format(step_loss))\n",
    "        total_train_loss += step_loss\n",
    "        global_step += 1\n",
    "    avg_train_loss = total_train_loss / len(train_dataloader)\n",
    "    # Measure how long this epoch took.\n",
    "    print(\"\")\n",
    "    print(\"  Average training loss: {0:.2f}\".format(avg_train_loss))\n",
    "\n",
    "    print(\"\")\n",
    "    print(\"Running Validation...\")\n",
    "    model.eval()\n",
    "\n",
    "    # Tracking variables\n",
    "    total_eval_accuracy = 0.0\n",
    "    total_eval_loss = 0\n",
    "    nb_eval_steps = 0\n",
    "    for step, batch in enumerate(validation_dataloader):\n",
    "        #val_h = model.init_hidden(len(batch[0]), device)\n",
    "        #val_h = tuple([each.data for each in val_h])\n",
    "        b_input_ids = batch[0]\n",
    "        b_input_ids = torch.tensor(b_input_ids).to(device).long()\n",
    "        b_labels = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            # Forward pass, calculate logit predictions.\n",
    "            loss, logits = model(b_input_ids, b_labels)\n",
    "        total_eval_loss += loss\n",
    "        batch_acc = get_accuracy_from_logits(logits, b_labels)\n",
    "        batch_acc2 = multi_acc(logits, b_labels)\n",
    "        print(\"Batch accuracy: {0:.2f}\".format(batch_acc))\n",
    "        total_eval_accuracy += batch_acc\n",
    "    \n",
    "    # Calculate the average loss over all of the batches.\n",
    "    avg_val_accuracy = total_eval_accuracy / len(validation_dataloader)\n",
    "    print(\"  Accuracy: {0:.2f}\".format(avg_val_accuracy))\n",
    "    \n",
    "    if avg_val_accuracy > best_val_acc:\n",
    "        print(f\"New best model, saving it!\")\n",
    "        if avg_val_accuracy > best_curr_val:\n",
    "            best_curr_val = avg_val_accuracy\n",
    "        if last_saved_model:\n",
    "            shutil.rmtree(last_saved_model)\n",
    "        model_path = Path(\n",
    "            FULL_PATH_TO_MODELS,\n",
    "            f\"base-dataset-{dataset}-{save_name}\"\n",
    "        )\n",
    "        last_saved_model = model_path\n",
    "        model_path.mkdir(parents=True, exist_ok=True)\n",
    "        best_val_acc = avg_val_accuracy\n",
    "        torch.save(model, join(model_path, \"best-model.pth\"))\n",
    "        best_epoch = epoch_i\n",
    "        n_epochs_no_improvement = 0\n",
    "    elif avg_val_accuracy > best_curr_val:\n",
    "        best_curr_val = avg_val_accuracy\n",
    "        n_epochs_no_improvement = 0\n",
    "    else:\n",
    "        n_epochs_no_improvement += 1\n",
    "        print(f\"The model does not improve for {n_epochs_no_improvement} epochs!\")\n",
    "\n",
    "    if n_epochs_no_improvement > patience:\n",
    "        print(f\"====>Stopping training, the model did not improve for {n_epochs_no_improvement}\\n====>Best epoch: {best_epoch + 1}.\")\n",
    "        break\n",
    "    scheduler.step(total_eval_loss)\n",
    "print(\"\")\n",
    "print(\"Training complete!\")\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model_path: Path,\n",
    "    dataset: str,\n",
    "    batch_size: int,\n",
    "    labels_dict,\n",
    "    device: torch.device\n",
    "):\n",
    "\n",
    "    print(f\"====Loading dataset for testing\")\n",
    "    test_corpus = NLPDataset(dataset, \"test\", sentence_max_len, labels_dict = labels_dict, vocab= voc)\n",
    "\n",
    "    test_dataloader = DataLoader(\n",
    "        test_corpus,\n",
    "        batch_size=batch_size,\n",
    "        #sampler = RandomSampler(test_corpus),\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    print(f\"====Loading model for testing\")\n",
    "    model = torch.load(join(model_path, \"best-model.pth\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    test_labels = []\n",
    "    logits_list = []\n",
    "\n",
    "    def _list_from_tensor(tensor):\n",
    "        if tensor.numel() == 1:\n",
    "            return [tensor.item()]\n",
    "        return list(tensor.cpu().detach().numpy())\n",
    "\n",
    "    print(\"====Testing model...\")\n",
    "    for batch in test_dataloader:\n",
    "        #h = model.init_hidden(len(batch[0]), device)\n",
    "        #h = tuple([each.data for each in val_h])\n",
    "        b_input_ids = batch[0]\n",
    "        b_input_ids = torch.tensor(b_input_ids).to(device).long()\n",
    "        b_labels = batch[1].to(device)\n",
    "        with torch.no_grad():\n",
    "            #h = tuple([each.data for each in h])\n",
    "            loss, logits = model(b_input_ids, b_labels)\n",
    "            preds = np.argmax(logits.cpu(), axis=1) # Convert one-hot to index\n",
    "            b_labels = b_labels.int()\n",
    "            pred_labels.extend(_list_from_tensor(preds))\n",
    "            test_labels.extend(_list_from_tensor(b_labels))\n",
    "        logits_list.extend(_list_from_tensor(logits))\n",
    "\n",
    "    print(classification_report(test_labels, pred_labels, labels=list(labels_dict.values()), target_names=np.array(list(labels_dict.keys())), digits=3, output_dict=False))\n",
    "    logits_list = expit(logits_list)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train_dataloader\n",
    "del validation_dataloader\n",
    "del train_corpus\n",
    "del val_corpus\n",
    "del model\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Loading dataset for testing\n",
      "====Loading model for testing\n",
      "====Testing model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:39: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n",
      "/usr/local/lib/python3.6/dist-packages/sklearn/metrics/_classification.py:1245: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                  precision    recall  f1-score   support\n",
      "\n",
      "                              Sintomas.Genrico.Sky no funciona      0.862     0.912     0.886      8357\n",
      "                                    Sintomas.Genrico.Instalao      0.972     0.961     0.967       647\n",
      "                                Sintomas.Genrico.Canal no pega      0.871     0.887     0.879      5967\n",
      "                    Sintomas.Genrico.Equipamento no funciona G      0.924     0.916     0.920      2318\n",
      "                                     Sintomas.Genrico.Sem sinal      0.928     0.935     0.931     14552\n",
      "                               Sintomas.Qualificado.Cancelamento      0.916     0.923     0.919      1847\n",
      "                           Sintomas.Qualificado.Outros problemas      0.692     0.582     0.632       729\n",
      "                              Sintomas.Qualificado.NoTc_fatura      0.852     0.788     0.818      1451\n",
      "                          Sintomas.Qualificado.Mudana de cmodo      0.936     0.925     0.930      1975\n",
      "                        Sintomas.Genrico.Equipamento queimado G      0.960     0.968     0.964      2106\n",
      "                      Sintomas.Genrico.Problema com equipamento      0.960     0.953     0.956      9645\n",
      "                        Sintomas.Genrico.Equipamento quebrado G      0.901     0.919     0.910      1441\n",
      "              Sintomas.Qualificado.Controle no funciona para tv      0.698     0.692     0.695       107\n",
      "                           Sintomas.Genrico.Falar com atendente      0.961     0.958     0.959      8262\n",
      "                            Sintomas.Genrico.Problema com canal      0.940     0.922     0.931      3547\n",
      "                       Sintomas.Qualificado.Tcnico no resolveu      0.558     0.319     0.406        91\n",
      "                          Sintomas.Genrico.Troca de equipamento      0.932     0.952     0.942      3737\n",
      "                              Sintomas.Qualificado.NoTc_outros      0.827     0.618     0.708       186\n",
      "                                Sintomas.Qualificado.Banda larga      0.978     0.980     0.979      2590\n",
      "                                       Sintomas.Genrico.Mudana      0.911     0.912     0.912       891\n",
      "                          Sintomas.Qualificado.Ausncia de sinal      0.972     0.983     0.977     10158\n",
      "                         Sintomas.Qualificado.Cabos e conectores      0.965     0.933     0.949      1558\n",
      "                           Sintomas.Qualificado.Tcnico no veio      0.860     0.862     0.861      1474\n",
      "                     Sintomas.Qualificado.NoTc ponto adicional      0.864     0.843     0.853      2049\n",
      "                        Sintomas.Qualificado.Mudana de endereo      0.956     0.964     0.959      3343\n",
      "                          Sintomas.Genrico.Canal Globo no pega      0.522     0.543     0.532       304\n",
      "                           Sintomas.Qualificado.Controle perdido      0.865     0.941     0.901       306\n",
      "                          Sintomas.Qualificado.Tela com chuvisco      0.563     0.402     0.469       234\n",
      "                         Sintomas.Genrico.Mudana de endereo G      0.987     0.985     0.986      2501\n",
      "                           Sintomas.Genrico.Problema com imagem      0.949     0.932     0.940      6605\n",
      "         Sintomas.Qualificado.Equipamento liga e desliga sozinho      0.811     0.857     0.833       455\n",
      "                                   Sintomas.Qualificado.Cdigo 6      0.815     0.755     0.784       905\n",
      "                       Sintomas.Qualificado.Equipamento no liga      0.905     0.950     0.927      1816\n",
      "                               Sintomas.Qualificado.NoTc_plano      0.715     0.717     0.716      1683\n",
      "                          Sintomas.Qualificado.Programao local      0.830     0.850     0.840       380\n",
      "                                   Sintomas.Qualificado.Gravao      0.804     0.788     0.796       997\n",
      "                                 Sintomas.Qualificado.Sky Online      0.885     0.900     0.892      1926\n",
      "                      Sintomas.Genrico.Canal comum no pega (G)      0.778     0.675     0.723      1200\n",
      "                   Sintomas.Genrico.Problema com visita tcnica      0.998     0.995     0.997      2193\n",
      "                       Sintomas.Genrico.Texto ou cdigo na tela      0.811     0.772     0.791      1694\n",
      "                              Sintomas.Qualificado.Cdigo 1-2-25      0.816     0.807     0.811       658\n",
      "                                 Sintomas.Qualificado.Tela preta      0.855     0.830     0.843       861\n",
      "                Sintomas.Qualificado.Travado no canal do cliente      0.672     0.704     0.687       506\n",
      "             Sintomas.Qualificado.Controle no funciona para sky      0.608     0.584     0.596       125\n",
      "                   Sintomas.Qualificado.Apenas imagem, sem udio      0.859     0.833     0.846       562\n",
      "              Sintomas.Qualificado.Canal PPV no est disponvel      0.860     0.896     0.878      1016\n",
      "                        Sintomas.Qualificado.Evento indisponvel      0.896     0.862     0.878       130\n",
      "                                  Sintomas.Qualificado.Cdigo 56      0.983     0.976     0.979       585\n",
      "                      Sintomas.Qualificado.Priorizar atendimento      0.772     0.832     0.801      1140\n",
      "                            Sintomas.Genrico.Problema Controle2      0.901     0.896     0.899      1661\n",
      "                           Sintomas.Genrico.Canal HD no pega G      0.835     0.838     0.837       697\n",
      "                       Sintomas.Qualificado.Reativar programao      0.906     0.800     0.850        60\n",
      "                                  Sintomas.Qualificado.Cdigo 77      0.736     0.885     0.804      1094\n",
      "                          Sintomas.Qualificado.NoTc upgrade hd      0.835     0.842     0.838       419\n",
      "Sintomas.Qualificado.Informaes e confirmao de visita tcnica      0.826     0.823     0.824       910\n",
      "                                   Sintomas.Qualificado.Cdigo 4      0.852     0.831     0.841       980\n",
      "                     Sintomas.Qualificado.Agendar visita tcnica      0.888     0.829     0.858       316\n",
      "                        Sintomas.Qualificado.Chip do equipamento      0.899     0.967     0.932        92\n",
      "                  Sintomas.Qualificado.Equipamento superaquecido      0.833     0.522     0.642        67\n",
      "                        Sintomas.Qualificado.Irritao ou Anatel      0.899     0.916     0.907       950\n",
      "                         Sintomas.Qualificado.Cdigo diagnstico      0.950     0.943     0.947       122\n",
      "                            Sintomas.Genrico.Tela monocromtica      0.872     0.727     0.793       187\n",
      "                           Sintomas.Genrico.Entendimento errado      0.822     0.717     0.766       322\n",
      "                                       Sintomas.Genrico.No sei      0.730     0.780     0.754       440\n",
      "                                    Sintomas.Genrico.Cdigo sim      0.762     0.716     0.738        67\n",
      "            Sintomas.Qualificado.Atualizao crtica de endereo      0.812     0.765     0.788        17\n",
      "                            Sintomas.Genrico.Problema com udio      0.928     0.940     0.934       301\n",
      "                             Sintomas.Qualificado.Senha - padro      0.690     0.833     0.755       120\n",
      "                                  Sintomas.Qualificado.Tela azul      0.829     0.903     0.864       134\n",
      "                  Sintomas.Qualificado.Mudana de posio antena      0.826     0.813     0.820       654\n",
      "                            Sintomas.Genrico.Problema de antena      0.866     0.855     0.861        83\n",
      "                             Sintomas.Qualificado.Aplicativo Sky      0.982     0.990     0.986       809\n",
      "                                 Sintomas.Genrico.Canal travado      0.842     0.860     0.851       477\n",
      "                Sintomas.Qualificado.Resolvido com sinal booster      0.780     0.703     0.739       212\n",
      "                          Sintomas.Qualificado.Legenda incorreta      0.686     0.800     0.738        30\n",
      "                                 Sintomas.Qualificado.Cdigo 109      0.957     0.968     0.963        93\n",
      "                        Sintomas.Qualificado.Equipamento travado      0.465     0.495     0.479        93\n",
      "                         Sintomas.Genrico.Mudana de instalao      1.000     1.000     1.000        98\n",
      "                       Sintomas.Genrico.Canal opcional no pega      0.745     0.712     0.728       222\n",
      "                                  Sintomas.Qualificado.Cdigo 19      0.841     0.755     0.796        49\n",
      "                             Sintomas.Genrico.Mudana de antena      0.924     0.952     0.938       372\n",
      "                              Sintomas.Qualificado.NoTc_compra      0.784     0.674     0.725       129\n",
      "                           Sintomas.Qualificado.NoTc sky livre      0.892     0.976     0.932       127\n",
      "                      Sintomas.Qualificado.Reset de senha padro      0.819     0.748     0.782       115\n",
      "                          Sintomas.Qualificado.Controle quebrado      0.808     0.609     0.694       138\n",
      "                                  Sintomas.Qualificado.Cdigo 14      0.847     0.649     0.735       111\n",
      "                        Sintomas.Qualificado.Guia de programao      0.938     0.924     0.931       409\n",
      "                             Sintomas.Qualificado.Numerao nova      0.860     0.792     0.825       101\n",
      "                      Sintomas.Qualificado.TV  HD, mas Sky  SD      0.789     0.728     0.757       268\n",
      "                          Sintomas.Genrico.Sem sinal nem cdigo      0.629     0.568     0.597       146\n",
      "                               Sintomas.Qualificado.Cancelar Sky      0.613     0.380     0.469        50\n",
      "                                    Sintomas.Qualificado.Recarga      0.417     0.185     0.256        27\n",
      "                       Sintomas.Qualificado.Novo Controle Pedido      0.844     0.849     0.846       146\n",
      "                       Sintomas.Qualificado.Equipamento queimado      0.679     0.735     0.706       147\n",
      "                            Sintomas.Genrico.Problema com senha      0.997     0.983     0.990       291\n",
      "                            Sintomas.Qualificado.NoTc_cadastro      0.774     0.702     0.736       292\n",
      "                         Sintomas.Qualificado.Criar senha padro      0.750     0.450     0.563        20\n",
      "                              Sintomas.Qualificado.Alterar udio      0.910     0.887     0.898       204\n",
      "                        Sintomas.Qualificado.Canal fora da grade      0.804     0.781     0.792       342\n",
      "                          Sintomas.Genrico.Problema com legenda      0.979     0.944     0.962       252\n",
      "                              Sintomas.Qualificado.Problema tudo      0.902     0.821     0.859       145\n",
      "                                   Sintomas.Qualificado.Cdigo 9      0.750     0.667     0.706         9\n",
      "                      Sintomas.Qualificado.Imagem preto e branco      0.910     0.747     0.821        95\n",
      "                               Sintomas.Qualificado.Nmero da OS      0.000     0.000     0.000         2\n",
      "                     Sintomas.Genrico.Atualizao de endereo G      0.971     0.895     0.932        76\n",
      "                 Sintomas.Qualificado.Habilitar recurso de senha      0.744     0.782     0.762        78\n",
      "                     Sintomas.Genrico.Canal adulto no pega (G)      0.649     0.706     0.676        34\n",
      "                   Sintomas.Genrico.Problema com troca de canal      0.364     0.211     0.267        19\n",
      "                         Sintomas.Qualificado.Cliente est longe      0.350     0.219     0.269        32\n",
      "    Sintomas.Qualificado.Procurando sinal sintonizador terrestre      0.846     0.710     0.772        31\n",
      "                      Sintomas.Qualificado.Equipamento com rudo      0.696     0.762     0.727        21\n",
      "                                  Sintomas.Qualificado.Cdigo 13      0.947     0.783     0.857        23\n",
      "                         Sintomas.Qualificado.Travado exceto 200      0.400     0.118     0.182        17\n",
      "                Sintomas.Qualificado.Legenda no aparece na tela      0.773     0.829     0.800        70\n",
      "                      Sintomas.Qualificado.Ativar closed caption      0.000     0.000     0.000         6\n",
      "                            Sintomas.Genrico.Promessa de oferta      0.250     0.154     0.190        13\n",
      "                       Sintomas.Qualificado.Ausncia sinal geral      0.750     0.571     0.649        21\n",
      "                             Sintomas.Qualificado.udio atrasado      0.667     0.333     0.444         6\n",
      "                      Sintomas.Qualificado.Lentido trocar canal      0.455     0.625     0.526         8\n",
      "                    Sintomas.Qualificado.Msg carregando contedo      1.000     0.667     0.800         3\n",
      "                   Sintomas.Genrico.Problema com closed caption      1.000     1.000     1.000         4\n",
      "\n",
      "                                                        accuracy                          0.906    133986\n",
      "                                                       macro avg      0.802     0.765     0.778    133986\n",
      "                                                    weighted avg      0.906     0.906     0.906    133986\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(last_saved_model, dataset, batch_size, labels_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
