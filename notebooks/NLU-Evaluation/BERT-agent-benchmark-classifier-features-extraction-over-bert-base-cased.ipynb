{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa\n",
    "https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from os.path import join\n",
    "import torch\n",
    "from nlpClassifiers.data.dataset  import NLPDataset\n",
    "from nlpClassifiers.models.models import BertSentenceFeaturesModel\n",
    "#from torch.optim import AdamW, SGD\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import LayerNorm as BertLayerNorm\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle as pk\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import wandb\n",
    "import re\n",
    "from nlpClassifiers import settings\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model_path: Path,\n",
    "    dataset: str,\n",
    "    batch_size: int,\n",
    "    labels_dict,\n",
    "    device: torch.device\n",
    "):\n",
    "\n",
    "    print(f\"====Loading dataset for testing\")\n",
    "    test_corpus = NLPDataset(dataset, \"test\", sentence_max_len, bert_path, labels_dict)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_corpus,\n",
    "        batch_size=batch_size,\n",
    "        sampler = RandomSampler(test_corpus),\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "        drop_last=True\n",
    "    )\n",
    "\n",
    "    print(f\"====Loading model for testing\")\n",
    "    model = torch.load(join(model_path, \"best-model.pth\"))\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "    pred_labels = []\n",
    "    test_labels = []\n",
    "    logits_list = []\n",
    "\n",
    "    def _list_from_tensor(tensor):\n",
    "        if tensor.numel() == 1:\n",
    "            return [tensor.item()]\n",
    "        return list(tensor.cpu().detach().numpy())\n",
    "\n",
    "    print(\"====Testing model...\")\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_segment_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            loss, logits= model(b_input_ids,  b_segment_ids, b_labels)\n",
    "            preds = np.argmax(logits.cpu(), axis=1) # Convert one-hot to index\n",
    "            b_labels = b_labels.int()\n",
    "            pred_labels.extend(_list_from_tensor(preds))\n",
    "            test_labels.extend(_list_from_tensor(b_labels))\n",
    "        logits_list.extend(_list_from_tensor(logits))\n",
    "\n",
    "    print(classification_report(test_labels, pred_labels, labels=list(labels_dict.values()), target_names=np.array(list(labels_dict.keys())), digits=3))\n",
    "    logits_list = expit(logits_list)\n",
    "\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_accuracy_from_logits(logits, labels):\n",
    "    acc = (labels.cpu() == logits.cpu().argmax(-1)).float().detach().numpy()\n",
    "    return float(100 * acc.sum() / len(acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/virtual-operator'\n",
    "MODELS_PATH = '../../models/virtual-operator/bert-base-portuguese-tapt-classifier/'\n",
    "PATH_TO_BERT = '../../models/virtual-operator/bertimbau-adaptive-base-finetuned/'\n",
    "TRAIN_DATASET = os.path.join(DATA_PATH, 'train.csv')\n",
    "VAL_DATASET = os.path.join(DATA_PATH, 'val.csv')\n",
    "TEST_DATASET  = os.path.join(DATA_PATH, 'test.csv')\n",
    "PATH_TO_VIRTUAL_OPERATOR_MODELS =  \"../../models/virtual-operator\"\n",
    "PATH_TO_AGENT_BENCHMARK_MODELS = \"../../models/agent-benchmark\"\n",
    "PATH_TO_ML_PT_MODELS = \"../../models/mercado-livre-pt-only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "dataset = 'agent-benchmark'\n",
    "save_name = 'bert-features-classifier-cls-agent-benchmark'\n",
    "bert_path = 'bert-base-cased'\n",
    "batch_size = 16\n",
    "sentence_max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_TO_MODELS = {\"virtual-operator\": PATH_TO_VIRTUAL_OPERATOR_MODELS, \"agent-benchmark\": PATH_TO_AGENT_BENCHMARK_MODELS, \"mercado-livre-pt\": PATH_TO_ML_PT_MODELS}\n",
    "FULL_PATH_TO_MODELS = join(BASE_PATH_TO_MODELS[dataset], \"bert-base-portuguese-tapt-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{gpu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\n",
    "    FULL_PATH_TO_MODELS, \n",
    "    f\"base-dataset-{dataset}-{save_name}\"\n",
    ")\n",
    "last_saved_model = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = NLPDataset(dataset, \"train\", sentence_max_len, bert_path)\n",
    "labels_dict = train_corpus.labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Loading dataset for testing\n",
      "====Loading model for testing\n",
      "====Testing model...\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    calendar_notification      0.386     0.378     0.382        45\n",
      "     transport_directions      0.538     0.512     0.525        41\n",
      "           cooking_recipe      0.825     0.733     0.776        45\n",
      "               radio_play      0.782     0.816     0.799       136\n",
      "             lists_remove      0.870     0.827     0.848        81\n",
      "               news_query      0.725     0.740     0.732       146\n",
      "         cooking_question      0.580     0.644     0.611        45\n",
      "           contacts_query      0.712     0.712     0.712        52\n",
      "             general_joke      0.909     0.889     0.899        45\n",
      "               audio_mute      0.737     0.737     0.737        38\n",
      "            QA_open_query      0.421     0.429     0.425       119\n",
      "          transport_train      0.824     0.884     0.853        95\n",
      "         weather_question      0.544     0.782     0.642        87\n",
      "           music_question      0.721     0.705     0.713        44\n",
      "               QA_factoid      0.781     0.733     0.757       195\n",
      "              email_query      0.957     0.886     0.920       176\n",
      "              lists_query      0.860     0.842     0.851        95\n",
      "     general_conversation      0.659     0.515     0.578       165\n",
      "recommendation_locations       0.714     0.698     0.706        43\n",
      "       calendar_set_event      0.854     0.796     0.824       191\n",
      "          weather_request      0.690     0.649     0.669       168\n",
      "            QA_definition      0.863     0.863     0.863       124\n",
      "           takeaway_query      0.897     0.745     0.814        47\n",
      "                  IOT_hue      0.950     0.977     0.963       214\n",
      "           datetime_query      0.840     0.821     0.830       134\n",
      "              email_reply      0.818     0.837     0.828        43\n",
      "                 QA_maths      0.732     0.789     0.759        38\n",
      "             lists_adding      0.788     0.765     0.776        34\n",
      "             QA_celebrity      0.776     0.833     0.804       108\n",
      "               music_play      0.820     0.783     0.801       244\n",
      "                game_play      0.774     0.857     0.814        56\n",
      "                 IOT_wemo      0.795     0.854     0.824        41\n",
      "          general_mistake      0.556     0.510     0.532        49\n",
      "           music_settings      0.643     0.540     0.587        50\n",
      "              alarm_query      0.535     0.622     0.575        37\n",
      "    recommendation_movies      0.486     0.419     0.450        43\n",
      "    calendar_delete_event      0.785     0.877     0.828       146\n",
      "             social_query      0.830     0.848     0.839        46\n",
      "           takeaway_order      0.608     0.705     0.653        44\n",
      "        transport_traffic      0.857     0.837     0.847        43\n",
      "           audiobook_play      0.750     0.764     0.757        55\n",
      "         email_send_email      0.877     0.922     0.899       116\n",
      "         general_feedback      0.738     0.696     0.716       138\n",
      "               IOT_coffee      0.891     0.980     0.933        50\n",
      "            podcasts_play      0.951     0.812     0.876        96\n",
      "             alarm_remove      0.711     0.675     0.692        40\n",
      "                alarm_set      0.739     0.708     0.723        48\n",
      "           reminder_query      0.618     0.739     0.673        46\n",
      "              social_post      0.903     0.879     0.891       116\n",
      "           lists_creating      0.810     0.829     0.819        41\n",
      "        datetime_question      0.609     0.651     0.629        43\n",
      "                 QA_stock      0.750     0.900     0.818        50\n",
      "        general_confusion      0.569     0.755     0.649        49\n",
      "        calendar_question      0.641     0.595     0.617        42\n",
      "             audio_volume      0.603     0.686     0.642        51\n",
      "    news_set_notification      0.487     0.452     0.469        42\n",
      "   recommendation_events       0.529     0.628     0.574        43\n",
      "        music_preferences      0.705     0.663     0.683        83\n",
      "             IOT_cleaning      0.935     0.896     0.915        48\n",
      "     general_confirmation      0.459     0.395     0.425        43\n",
      "     calendar_query_event      0.670     0.615     0.641       122\n",
      "           transport_taxi      0.881     0.902     0.892        41\n",
      "             reminder_set      0.477     0.575     0.522        73\n",
      "         datetime_convert      0.743     0.743     0.743        35\n",
      "\n",
      "                 accuracy                          0.752      5104\n",
      "                macro avg      0.726     0.732     0.727      5104\n",
      "             weighted avg      0.755     0.752     0.752      5104\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(last_saved_model, dataset, batch_size, labels_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
