{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on https://mlexplained.com/2019/01/30/an-in-depth-tutorial-to-allennlp-from-basics-to-elmo-and-bert/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install allennlp==0.9.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "import logging\n",
    "import numpy as np\n",
    "import os\n",
    "import pandas as pd\n",
    "import sys\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from allennlp.common.checks import ConfigurationError\n",
    "from allennlp.data import Instance\n",
    "from allennlp.data.fields import LabelField, TextField, Field, ArrayField\n",
    "from allennlp.data.instance import Instance\n",
    "from allennlp.data.iterators import BasicIterator, DataIterator, BucketIterator\n",
    "from allennlp.data.tokenizers import Tokenizer, WordTokenizer, Token\n",
    "from allennlp.data.tokenizers.word_splitter import JustSpacesWordSplitter\n",
    "from allennlp.data.token_indexers import TokenIndexer, SingleIdTokenIndexer\n",
    "from allennlp.data.vocabulary import Vocabulary\n",
    "from allennlp.training.metrics import CategoricalAccuracy\n",
    "from allennlp.common.file_utils import cached_path\n",
    "from allennlp.data.dataset_readers.dataset_reader import DatasetReader\n",
    "from allennlp.models import Model\n",
    "from allennlp.modules.seq2vec_encoders import Seq2VecEncoder, PytorchSeq2VecWrapper\n",
    "from allennlp.modules.text_field_embedders import TextFieldEmbedder, BasicTextFieldEmbedder\n",
    "from allennlp.data.tokenizers.word_splitter import SpacyWordSplitter\n",
    "from allennlp.data.token_indexers.elmo_indexer import ELMoCharacterMapper, ELMoTokenCharactersIndexer\n",
    "from allennlp.modules.token_embedders import ElmoTokenEmbedder\n",
    "from allennlp.nn import util as nn_util\n",
    "from allennlp.nn.util import get_text_field_mask\n",
    "from allennlp.training.trainer import Trainer\n",
    "from functools import partial\n",
    "from overrides import overrides\n",
    "from pathlib import Path\n",
    "from scipy.special import expit # the sigmoid function\n",
    "from sklearn.metrics import classification_report\n",
    "from tqdm import tqdm\n",
    "from typing import Dict, List, Callable, Iterable\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = logging.getLogger(__name__)  # pylint: disable=invalid-name\n",
    "\n",
    "class AgentBenchmarkDatasetReader(DatasetReader):\n",
    "    def __init__(self,\n",
    "                 config,\n",
    "                 tokenizer: Callable[[str], List[str]]=lambda x: x.split(),\n",
    "                 token_indexers: Dict[str, TokenIndexer] = None) -> None:\n",
    "        super().__init__(lazy=False)\n",
    "        self._tokenizer = tokenizer or WordTokenizer(JustSpacesWordSplitter())\n",
    "        self._token_indexers = token_indexers or {\"tokens\": SingleIdTokenIndexer()}\n",
    "        self._config = config\n",
    "\n",
    "    @overrides\n",
    "    def _read(self, file_path):\n",
    "        logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "        with open(cached_path(file_path), mode=\"r\", encoding='utf-8') as data_file:\n",
    "            logger.info(\"Reading instances from lines in file at: %s\", file_path)\n",
    "            i = 0\n",
    "            for line in data_file:\n",
    "                i+=1\n",
    "                if self._config.testing: \n",
    "                    if i == 50000:\n",
    "                       break\n",
    "                line = line.strip(\"\\n\")\n",
    "                if not line:\n",
    "                    continue\n",
    "                line_data = line.split(\";\")\n",
    "                if line_data[0] == \"utterance\":\n",
    "                    continue\n",
    "                utterance = line_data[0]\n",
    "                label = line_data[1]\n",
    "\n",
    "                if utterance == \"\":\n",
    "                    break\n",
    "\n",
    "                yield self.text_to_instance(\n",
    "                        [Token(x) for x in self._tokenizer(utterance)], label)\n",
    "\n",
    "    @overrides\n",
    "    def text_to_instance(self,  # type: ignore\n",
    "                         tokens:List[Token],\n",
    "                         label: str = None) -> Instance:\n",
    "        # pylint: disable=arguments-differ\n",
    "        sentence_field = TextField(tokens, self._token_indexers)\n",
    "        fields = { \"tokens\" : sentence_field}\n",
    "\n",
    "        if label is not None:\n",
    "            fields['label'] = LabelField(label, \"labels\")\n",
    "\n",
    "        return Instance(fields)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "ELMO_MODEL_PATH=\"../../models/agent-benchmark/elmo-model.th\"\n",
    "ELMO_VOCAB_PATH=\"../../models/agent-benchmark/elmo-vocabulary\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/agent-benchmark'\n",
    "TRAIN_DATASET = os.path.join(DATA_PATH, 'train.csv')\n",
    "VAL_DATASET = os.path.join(DATA_PATH, 'val.csv')\n",
    "TEST_DATASET  = os.path.join(DATA_PATH, 'test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def seed_everything(seed=10):\n",
    "    random.seed(seed)\n",
    "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed_everything()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config(dict):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)\n",
    "        for k, v in kwargs.items():\n",
    "            setattr(self, k, v)\n",
    "    \n",
    "    def set(self, key, val):\n",
    "        self[key] = val\n",
    "        setattr(self, key, val)\n",
    "        \n",
    "config = Config(\n",
    "    lazy=False,\n",
    "    testing=False,\n",
    "    seed=1,\n",
    "    batch_size=512,\n",
    "    lr=3e-2,\n",
    "    epochs=30,\n",
    "    hidden_sz=300,\n",
    "    max_seq_len=82, # necessary to limit memory usage\n",
    "    max_vocab_size=30000,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "USE_GPU =torch.cuda.is_available()\n",
    "gpu=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.4581, 0.4829, 0.3125],\n",
      "        [0.6150, 0.2139, 0.4118]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    " print(torch.rand(2,3).cuda())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7.1\n"
     ]
    }
   ],
   "source": [
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fbd7c98ceb8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.manual_seed(config.seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare token handlers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the token indexer is responsible for mapping tokens to integers\n",
    "token_indexer = ELMoTokenCharactersIndexer()\n",
    "\n",
    "def tokenizer(x: str):\n",
    "    return [w.text for w in\n",
    "            SpacyWordSplitter(language='en_core_web_sm', \n",
    "                              pos_tags=False).split_words(x)[:config.max_seq_len]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "18415it [00:06, 3055.40it/s]\n",
      "2047it [00:00, 3281.18it/s]\n",
      "5116it [00:01, 3188.80it/s]\n"
     ]
    }
   ],
   "source": [
    "reader = AgentBenchmarkDatasetReader(config, tokenizer=tokenizer,\n",
    "    token_indexers={\"tokens\": token_indexer})\n",
    "train_dataset = reader.read(TRAIN_DATASET)\n",
    "val_dataset = reader.read(VAL_DATASET)\n",
    "test_dataset = reader.read(TEST_DATASET)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'tokens': [where, is, my, meeting, today, located],\n",
       " '_token_indexers': {'tokens': <allennlp.data.token_indexers.elmo_indexer.ELMoTokenCharactersIndexer at 0x7fbd96a42e10>},\n",
       " '_indexed_tokens': None,\n",
       " '_indexer_name_to_indexed_token': None,\n",
       " '_token_index_to_indexer_name': None}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(train_dataset[0].fields[\"tokens\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 18415/18415 [00:00<00:00, 290636.52it/s]\n"
     ]
    }
   ],
   "source": [
    "vocab = Vocabulary.from_instances(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'_padding_token': '@@PADDING@@',\n",
       " '_oov_token': '@@UNKNOWN@@',\n",
       " '_non_padded_namespaces': {'*labels', '*tags'},\n",
       " '_token_to_index': _TokenToIndexDefaultDict(None,\n",
       "                          {'labels': {'music_play': 0,\n",
       "                            'IOT_hue': 1,\n",
       "                            'QA_factoid': 2,\n",
       "                            'calendar_set_event': 3,\n",
       "                            'email_query': 4,\n",
       "                            'weather_request': 5,\n",
       "                            'general_conversation': 6,\n",
       "                            'news_query': 7,\n",
       "                            'calendar_delete_event': 8,\n",
       "                            'radio_play': 9,\n",
       "                            'general_feedback': 10,\n",
       "                            'datetime_query': 11,\n",
       "                            'QA_definition': 12,\n",
       "                            'calendar_query_event': 13,\n",
       "                            'QA_open_query': 14,\n",
       "                            'email_send_email': 15,\n",
       "                            'social_post': 16,\n",
       "                            'QA_celebrity': 17,\n",
       "                            'podcasts_play': 18,\n",
       "                            'transport_train': 19,\n",
       "                            'lists_query': 20,\n",
       "                            'weather_question': 21,\n",
       "                            'music_preferences': 22,\n",
       "                            'lists_remove': 23,\n",
       "                            'reminder_set': 24,\n",
       "                            'game_play': 25,\n",
       "                            'audiobook_play': 26,\n",
       "                            'contacts_query': 27,\n",
       "                            'audio_volume': 28,\n",
       "                            'music_settings': 29,\n",
       "                            'QA_stock': 30,\n",
       "                            'IOT_coffee': 31,\n",
       "                            'general_mistake': 32,\n",
       "                            'general_confusion': 33,\n",
       "                            'alarm_set': 34,\n",
       "                            'IOT_cleaning': 35,\n",
       "                            'takeaway_query': 36,\n",
       "                            'social_query': 37,\n",
       "                            'reminder_query': 38,\n",
       "                            'calendar_notification': 39,\n",
       "                            'cooking_recipe': 40,\n",
       "                            'cooking_question': 41,\n",
       "                            'general_joke': 42,\n",
       "                            'music_question': 43,\n",
       "                            'takeaway_order': 44,\n",
       "                            'recommendation_events ': 45,\n",
       "                            'recommendation_movies': 46,\n",
       "                            'datetime_question': 47,\n",
       "                            'recommendation_locations ': 48,\n",
       "                            'transport_traffic': 49,\n",
       "                            'email_reply': 50,\n",
       "                            'general_confirmation': 51,\n",
       "                            'calendar_question': 52,\n",
       "                            'news_set_notification': 53,\n",
       "                            'lists_creating': 54,\n",
       "                            'transport_taxi': 55,\n",
       "                            'IOT_wemo': 56,\n",
       "                            'transport_directions': 57,\n",
       "                            'alarm_remove': 58,\n",
       "                            'audio_mute': 59,\n",
       "                            'QA_maths': 60,\n",
       "                            'alarm_query': 61,\n",
       "                            'datetime_convert': 62,\n",
       "                            'lists_adding': 63}}),\n",
       " '_index_to_token': _IndexToTokenDefaultDict(None,\n",
       "                          {'labels': {0: 'music_play',\n",
       "                            1: 'IOT_hue',\n",
       "                            2: 'QA_factoid',\n",
       "                            3: 'calendar_set_event',\n",
       "                            4: 'email_query',\n",
       "                            5: 'weather_request',\n",
       "                            6: 'general_conversation',\n",
       "                            7: 'news_query',\n",
       "                            8: 'calendar_delete_event',\n",
       "                            9: 'radio_play',\n",
       "                            10: 'general_feedback',\n",
       "                            11: 'datetime_query',\n",
       "                            12: 'QA_definition',\n",
       "                            13: 'calendar_query_event',\n",
       "                            14: 'QA_open_query',\n",
       "                            15: 'email_send_email',\n",
       "                            16: 'social_post',\n",
       "                            17: 'QA_celebrity',\n",
       "                            18: 'podcasts_play',\n",
       "                            19: 'transport_train',\n",
       "                            20: 'lists_query',\n",
       "                            21: 'weather_question',\n",
       "                            22: 'music_preferences',\n",
       "                            23: 'lists_remove',\n",
       "                            24: 'reminder_set',\n",
       "                            25: 'game_play',\n",
       "                            26: 'audiobook_play',\n",
       "                            27: 'contacts_query',\n",
       "                            28: 'audio_volume',\n",
       "                            29: 'music_settings',\n",
       "                            30: 'QA_stock',\n",
       "                            31: 'IOT_coffee',\n",
       "                            32: 'general_mistake',\n",
       "                            33: 'general_confusion',\n",
       "                            34: 'alarm_set',\n",
       "                            35: 'IOT_cleaning',\n",
       "                            36: 'takeaway_query',\n",
       "                            37: 'social_query',\n",
       "                            38: 'reminder_query',\n",
       "                            39: 'calendar_notification',\n",
       "                            40: 'cooking_recipe',\n",
       "                            41: 'cooking_question',\n",
       "                            42: 'general_joke',\n",
       "                            43: 'music_question',\n",
       "                            44: 'takeaway_order',\n",
       "                            45: 'recommendation_events ',\n",
       "                            46: 'recommendation_movies',\n",
       "                            47: 'datetime_question',\n",
       "                            48: 'recommendation_locations ',\n",
       "                            49: 'transport_traffic',\n",
       "                            50: 'email_reply',\n",
       "                            51: 'general_confirmation',\n",
       "                            52: 'calendar_question',\n",
       "                            53: 'news_set_notification',\n",
       "                            54: 'lists_creating',\n",
       "                            55: 'transport_taxi',\n",
       "                            56: 'IOT_wemo',\n",
       "                            57: 'transport_directions',\n",
       "                            58: 'alarm_remove',\n",
       "                            59: 'audio_mute',\n",
       "                            60: 'QA_maths',\n",
       "                            61: 'alarm_query',\n",
       "                            62: 'datetime_convert',\n",
       "                            63: 'lists_adding'}}),\n",
       " '_retained_counter': defaultdict(<function allennlp.data.vocabulary.Vocabulary.from_instances.<locals>.<lambda>()>,\n",
       "             {'labels': defaultdict(int,\n",
       "                          {'calendar_notification': 162,\n",
       "                           'transport_directions': 147,\n",
       "                           'cooking_recipe': 162,\n",
       "                           'radio_play': 502,\n",
       "                           'lists_remove': 290,\n",
       "                           'news_query': 525,\n",
       "                           'cooking_question': 162,\n",
       "                           'contacts_query': 193,\n",
       "                           'general_joke': 162,\n",
       "                           'audio_mute': 138,\n",
       "                           'QA_open_query': 431,\n",
       "                           'transport_train': 344,\n",
       "                           'weather_question': 316,\n",
       "                           'music_question': 158,\n",
       "                           'QA_factoid': 700,\n",
       "                           'email_query': 639,\n",
       "                           'lists_query': 344,\n",
       "                           'general_conversation': 593,\n",
       "                           'recommendation_locations ': 155,\n",
       "                           'calendar_set_event': 690,\n",
       "                           'weather_request': 604,\n",
       "                           'QA_definition': 444,\n",
       "                           'takeaway_query': 167,\n",
       "                           'IOT_hue': 768,\n",
       "                           'datetime_query': 485,\n",
       "                           'email_reply': 153,\n",
       "                           'QA_maths': 136,\n",
       "                           'lists_adding': 123,\n",
       "                           'QA_celebrity': 388,\n",
       "                           'music_play': 876,\n",
       "                           'game_play': 201,\n",
       "                           'IOT_wemo': 148,\n",
       "                           'general_mistake': 175,\n",
       "                           'music_settings': 182,\n",
       "                           'alarm_query': 134,\n",
       "                           'recommendation_movies': 156,\n",
       "                           'calendar_delete_event': 525,\n",
       "                           'social_query': 165,\n",
       "                           'takeaway_order': 158,\n",
       "                           'transport_traffic': 155,\n",
       "                           'audiobook_play': 196,\n",
       "                           'email_send_email': 419,\n",
       "                           'general_feedback': 501,\n",
       "                           'IOT_coffee': 178,\n",
       "                           'podcasts_play': 345,\n",
       "                           'alarm_remove': 147,\n",
       "                           'alarm_set': 174,\n",
       "                           'reminder_query': 164,\n",
       "                           'social_post': 418,\n",
       "                           'lists_creating': 150,\n",
       "                           'datetime_question': 156,\n",
       "                           'QA_stock': 182,\n",
       "                           'general_confusion': 175,\n",
       "                           'calendar_question': 151,\n",
       "                           'audio_volume': 184,\n",
       "                           'news_set_notification': 151,\n",
       "                           'recommendation_events ': 157,\n",
       "                           'music_preferences': 300,\n",
       "                           'IOT_cleaning': 173,\n",
       "                           'general_confirmation': 153,\n",
       "                           'calendar_query_event': 439,\n",
       "                           'transport_taxi': 150,\n",
       "                           'reminder_set': 268,\n",
       "                           'datetime_convert': 128})})}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_labels = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BucketIterator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator = BucketIterator(batch_size=config.batch_size, \n",
    "                          sorting_keys=[(\"tokens\", \"num_tokens\")],\n",
    "                         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = vocab.get_index_to_token_vocabulary('tokens')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = next(iter(iterator(train_dataset)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[259, 120, 105,  ..., 261, 261, 261],\n",
       "         [259, 106, 116,  ..., 261, 261, 261],\n",
       "         [259, 117, 105,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 107, 112,  ..., 261, 261, 261],\n",
       "         [259, 116, 110,  ..., 261, 261, 261],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259, 116, 105,  ..., 261, 261, 261],\n",
       "         [259, 110, 102,  ..., 261, 261, 261],\n",
       "         [259, 120, 112,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 113, 116,  ..., 261, 261, 261],\n",
       "         [259, 105, 112,  ..., 261, 261, 261],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        [[259, 120, 105,  ..., 261, 261, 261],\n",
       "         [259,  40, 116,  ..., 261, 261, 261],\n",
       "         [259,  99, 102,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 117, 120,  ..., 261, 261, 261],\n",
       "         [259, 110, 112,  ..., 261, 261, 261],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[259, 120, 105,  ..., 261, 261, 261],\n",
       "         [259,  40, 116,  ..., 261, 261, 261],\n",
       "         [259, 117, 105,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 101, 112,  ..., 261, 261, 261],\n",
       "         [259, 117, 112,  ..., 261, 261, 261],\n",
       "         [259, 102, 118,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259, 113, 109,  ..., 261, 261, 261],\n",
       "         [259, 117, 102,  ..., 261, 261, 261],\n",
       "         [259, 110, 102,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259,  61, 260,  ..., 261, 261, 261],\n",
       "         [259, 118, 111,  ..., 261, 261, 261],\n",
       "         [259,  63, 260,  ..., 261, 261, 261]],\n",
       "\n",
       "        [[259, 117, 105,  ..., 261, 261, 261],\n",
       "         [259, 106, 116,  ..., 261, 261, 261],\n",
       "         [259,  98, 260,  ..., 261, 261, 261],\n",
       "         ...,\n",
       "         [259, 103, 106,  ..., 261, 261, 261],\n",
       "         [259,  98, 100,  ..., 261, 261, 261],\n",
       "         [  0,   0,   0,  ...,   0,   0,   0]]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch[\"tokens\"][\"tokens\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineModel(Model):\n",
    "    def __init__(self, word_embeddings: TextFieldEmbedder,\n",
    "                 encoder: Seq2VecEncoder,\n",
    "                 out_sz: int):\n",
    "        super().__init__(vocab)\n",
    "        self.word_embeddings = word_embeddings\n",
    "        self.encoder = encoder\n",
    "        self.projection = nn.Linear(self.encoder.get_output_dim(), out_sz)\n",
    "        self.loss = torch.nn.CrossEntropyLoss()\n",
    "        self.metrics = {\n",
    "                \"accuracy\": CategoricalAccuracy()\n",
    "                #,\"accuracy3\": CategoricalAccuracy(top_k=3)\n",
    "        }\n",
    "        \n",
    "    def forward(self, tokens: Dict[str, torch.Tensor],\n",
    "                label: torch.Tensor) -> torch.Tensor:\n",
    "        \n",
    "        mask = get_text_field_mask(tokens)\n",
    "        embeddings = self.word_embeddings(tokens)\n",
    "        state = self.encoder(embeddings, mask)\n",
    "        class_logits = self.projection(state)\n",
    "        class_probabilities = F.softmax(class_logits)\n",
    "        \n",
    "        if label is not None:\n",
    "            if label.shape[0] == 1:\n",
    "                loss = self.loss(class_logits, label)\n",
    "            else:    \n",
    "                loss = self.loss(class_logits, label.squeeze(-1))\n",
    "        \n",
    "            for metric in self.metrics.values():\n",
    "                if label.shape[0] == 1:\n",
    "                    metric(class_logits, label)\n",
    "                else:\n",
    "                    metric(class_logits, label.squeeze(-1))\n",
    "        \n",
    "        output = {\"class_logits\": class_logits, \"class_probabilities\": class_probabilities, \"loss\": loss }\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "options_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_options.json'\n",
    "weight_file = 'https://s3-us-west-2.amazonaws.com/allennlp/models/elmo/2x4096_512_2048cnn_2xhighway/elmo_2x4096_512_2048cnn_2xhighway_weights.hdf5'\n",
    "\n",
    "elmo_embedder = ElmoTokenEmbedder(options_file, weight_file)\n",
    "word_embeddings = BasicTextFieldEmbedder({\"tokens\": elmo_embedder})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder: Seq2VecEncoder = PytorchSeq2VecWrapper(nn.LSTM(word_embeddings.get_output_dim(), config.hidden_sz, \n",
    "                                                        bidirectional=True, batch_first=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, num_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "if USE_GPU: model.cuda(gpu)\n",
    "else: model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = nn_util.move_to_device(batch, gpu if USE_GPU else -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokens = batch[\"tokens\"]\n",
    "labels = batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = get_text_field_mask(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.word_embeddings(tokens)\n",
    "state = model.encoder(embeddings, mask)\n",
    "class_logits = model.projection(state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 10, 1024])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.0715, -0.0903,  0.1213,  ..., -0.1529, -0.4159,  0.0479],\n",
       "        [ 0.0992, -0.2256,  0.5123,  ...,  0.1568, -0.1132,  0.0020],\n",
       "        [ 0.1715, -0.0616,  0.2655,  ...,  0.0372, -0.0193,  0.0616],\n",
       "        ...,\n",
       "        [ 0.0394, -0.0180,  0.3718,  ...,  0.2085,  0.0173,  0.0364],\n",
       "        [-0.1303,  0.0124,  0.3682,  ..., -0.0596, -0.1920,  0.1393],\n",
       "        [ 0.1596, -0.0093,  0.2025,  ..., -0.1315, -0.1240, -0.1617]],\n",
       "       device='cuda:1', grad_fn=<ViewBackward>)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'class_logits': tensor([[ 0.0067, -0.1262, -0.0408,  ..., -0.1524,  0.2003, -0.1028],\n",
       "         [-0.1304, -0.0588, -0.0402,  ..., -0.0188,  0.1288,  0.0141],\n",
       "         [ 0.0522,  0.0221, -0.1178,  ..., -0.0933,  0.2221,  0.0395],\n",
       "         ...,\n",
       "         [ 0.1004,  0.1618, -0.0251,  ..., -0.0758,  0.3149, -0.1048],\n",
       "         [-0.1265, -0.0896,  0.0097,  ..., -0.0556,  0.0498,  0.0794],\n",
       "         [ 0.0222,  0.0245,  0.0781,  ...,  0.0726,  0.0300, -0.0694]],\n",
       "        device='cuda:1', grad_fn=<AddmmBackward>),\n",
       " 'class_probabilities': tensor([[0.0154, 0.0135, 0.0147,  ..., 0.0131, 0.0187, 0.0138],\n",
       "         [0.0138, 0.0148, 0.0150,  ..., 0.0154, 0.0178, 0.0159],\n",
       "         [0.0164, 0.0159, 0.0138,  ..., 0.0142, 0.0194, 0.0162],\n",
       "         ...,\n",
       "         [0.0172, 0.0183, 0.0152,  ..., 0.0144, 0.0213, 0.0140],\n",
       "         [0.0139, 0.0144, 0.0159,  ..., 0.0149, 0.0165, 0.0170],\n",
       "         [0.0157, 0.0157, 0.0166,  ..., 0.0165, 0.0158, 0.0143]],\n",
       "        device='cuda:1', grad_fn=<SoftmaxBackward>),\n",
       " 'loss': tensor(4.1629, device='cuda:1', grad_fn=<NllLossBackward>)}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n"
     ]
    }
   ],
   "source": [
    "loss = model(**batch)[\"loss\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(4.1651, device='cuda:1', grad_fn=<NllLossBackward>)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[tensor([[-7.8140e-06,  2.9064e-05,  2.7688e-05,  ..., -1.7780e-05,\n",
       "           6.6326e-05,  3.1826e-05],\n",
       "         [-1.0603e-05,  2.6026e-05,  1.3244e-05,  ...,  7.4283e-06,\n",
       "          -1.2003e-05, -2.1034e-05],\n",
       "         [ 6.7452e-06,  9.7185e-06,  3.0878e-05,  ..., -2.3322e-05,\n",
       "          -1.6964e-05, -2.6364e-05],\n",
       "         ...,\n",
       "         [-1.1221e-05, -3.6577e-05, -5.3905e-06,  ...,  9.7437e-06,\n",
       "           1.5629e-05, -1.7851e-05],\n",
       "         [ 5.1697e-05, -4.1432e-05,  3.5090e-05,  ...,  1.2223e-04,\n",
       "          -5.5800e-05,  1.1447e-04],\n",
       "         [ 5.3943e-05, -1.0062e-04, -5.4458e-05,  ..., -2.4138e-05,\n",
       "           4.2068e-05,  3.3619e-05]], device='cuda:1'),\n",
       " tensor([[-4.9624e-06, -6.7475e-06,  1.0555e-05,  ...,  6.0959e-07,\n",
       "          -1.1160e-05,  3.8650e-06],\n",
       "         [-5.5328e-06,  3.0699e-06,  7.6127e-08,  ...,  8.8970e-06,\n",
       "           1.5602e-05, -8.0203e-08],\n",
       "         [ 7.8553e-06,  1.5743e-05, -6.6295e-06,  ..., -3.2441e-06,\n",
       "          -2.4200e-05, -2.0758e-07],\n",
       "         ...,\n",
       "         [-1.5920e-05,  4.4458e-06, -2.2492e-06,  ...,  1.4205e-05,\n",
       "          -2.8048e-05,  2.9188e-05],\n",
       "         [ 2.3752e-05, -3.4982e-06,  5.9811e-05,  ..., -2.7992e-05,\n",
       "           7.8096e-05, -1.9808e-05],\n",
       "         [-1.2573e-05, -1.8214e-06,  3.1446e-05,  ..., -2.4627e-05,\n",
       "           4.3801e-05,  1.7067e-05]], device='cuda:1'),\n",
       " tensor([-1.9372e-05, -2.3861e-05, -9.1835e-05,  ..., -8.3155e-05,\n",
       "          2.7856e-04,  2.0460e-04], device='cuda:1'),\n",
       " tensor([-1.9372e-05, -2.3861e-05, -9.1835e-05,  ..., -8.3155e-05,\n",
       "          2.7856e-04,  2.0460e-04], device='cuda:1'),\n",
       " tensor([[-1.3530e-05, -3.4271e-05,  4.2484e-05,  ..., -2.1517e-05,\n",
       "           8.2977e-05, -7.4117e-05],\n",
       "         [-5.5470e-06, -1.2094e-05, -1.1599e-05,  ...,  3.7009e-06,\n",
       "          -1.3320e-05, -3.1186e-05],\n",
       "         [ 1.3330e-05, -4.5689e-05,  2.7004e-06,  ...,  5.9843e-06,\n",
       "           2.5376e-05, -7.1510e-06],\n",
       "         ...,\n",
       "         [ 1.1350e-04, -1.9913e-05,  2.0410e-05,  ..., -2.7853e-05,\n",
       "           3.5782e-05,  6.2190e-05],\n",
       "         [-7.0531e-05, -5.1854e-05,  3.1118e-05,  ...,  4.8250e-05,\n",
       "          -7.4851e-06,  1.5955e-05],\n",
       "         [-6.6610e-05, -1.1566e-05, -2.5792e-05,  ..., -2.0956e-06,\n",
       "           2.8660e-06, -3.9909e-05]], device='cuda:1'),\n",
       " tensor([[ 9.2902e-06,  1.1417e-05,  8.8858e-06,  ..., -2.0551e-05,\n",
       "          -1.8524e-05, -1.7081e-05],\n",
       "         [-1.0485e-05,  4.3123e-06, -3.6895e-06,  ..., -1.0014e-05,\n",
       "          -1.0534e-05, -9.7474e-06],\n",
       "         [-2.2129e-05, -8.1213e-06, -2.4136e-07,  ...,  4.7545e-06,\n",
       "           5.1040e-06,  5.2227e-06],\n",
       "         ...,\n",
       "         [ 2.5614e-05, -2.2353e-05,  1.6185e-05,  ...,  5.4456e-06,\n",
       "           1.1702e-06, -3.8573e-06],\n",
       "         [ 2.5246e-05,  3.3645e-05, -2.7447e-06,  ...,  9.7870e-06,\n",
       "           2.5228e-05, -5.5885e-06],\n",
       "         [-3.8733e-06,  1.1605e-05,  2.0729e-06,  ...,  4.9705e-06,\n",
       "           1.5016e-06, -1.0338e-05]], device='cuda:1'),\n",
       " tensor([ 9.8761e-05,  8.5174e-05, -3.3823e-05,  ...,  5.4723e-05,\n",
       "         -9.5406e-05, -4.5474e-05], device='cuda:1'),\n",
       " tensor([ 9.8761e-05,  8.5174e-05, -3.3823e-05,  ...,  5.4723e-05,\n",
       "         -9.5406e-05, -4.5474e-05], device='cuda:1')]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[x.grad for x in list(model.encoder.parameters())]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRAIN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "optimizer = optim.Adam(model.parameters(), lr=config.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.training.trainer import Trainer\n",
    "\n",
    "trainer = Trainer(\n",
    "    model=model,\n",
    "    patience=5,\n",
    "    optimizer=optimizer,\n",
    "    iterator=iterator,\n",
    "    train_dataset=train_dataset,\n",
    "    validation_dataset=val_dataset,\n",
    "    cuda_device=gpu if USE_GPU else -1,\n",
    "    num_epochs=config.epochs,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 2.9354 ||: 100%|██████████| 36/36 [00:17<00:00,  2.06it/s]\n",
      "loss: 1.4570 ||: 100%|██████████| 4/4 [00:01<00:00,  2.13it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 1.3101 ||: 100%|██████████| 36/36 [00:21<00:00,  1.70it/s]\n",
      "loss: 1.1525 ||: 100%|██████████| 4/4 [00:01<00:00,  2.32it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 1.0423 ||: 100%|██████████| 36/36 [00:22<00:00,  1.58it/s]\n",
      "loss: 1.0346 ||: 100%|██████████| 4/4 [00:02<00:00,  1.72it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.9033 ||: 100%|██████████| 36/36 [00:18<00:00,  1.90it/s]\n",
      "loss: 0.9961 ||: 100%|██████████| 4/4 [00:01<00:00,  2.25it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.8208 ||: 100%|██████████| 36/36 [00:18<00:00,  1.98it/s]\n",
      "loss: 0.9628 ||: 100%|██████████| 4/4 [00:01<00:00,  2.25it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.7407 ||: 100%|██████████| 36/36 [00:19<00:00,  1.87it/s]\n",
      "loss: 0.9785 ||: 100%|██████████| 4/4 [00:01<00:00,  2.39it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.6964 ||: 100%|██████████| 36/36 [00:18<00:00,  1.96it/s]\n",
      "loss: 0.9520 ||: 100%|██████████| 4/4 [00:01<00:00,  2.26it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.6443 ||: 100%|██████████| 36/36 [00:18<00:00,  1.98it/s]\n",
      "loss: 0.9131 ||: 100%|██████████| 4/4 [00:01<00:00,  2.32it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.6025 ||: 100%|██████████| 36/36 [00:17<00:00,  2.00it/s]\n",
      "loss: 1.0069 ||: 100%|██████████| 4/4 [00:01<00:00,  2.37it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.6009 ||: 100%|██████████| 36/36 [00:17<00:00,  2.01it/s]\n",
      "loss: 0.9652 ||: 100%|██████████| 4/4 [00:01<00:00,  2.12it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.5632 ||: 100%|██████████| 36/36 [00:18<00:00,  2.00it/s]\n",
      "loss: 0.9595 ||: 100%|██████████| 4/4 [00:01<00:00,  2.45it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.5395 ||: 100%|██████████| 36/36 [00:17<00:00,  2.08it/s]\n",
      "loss: 0.9627 ||: 100%|██████████| 4/4 [00:01<00:00,  2.33it/s]\n",
      "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:435: UserWarning: Setting attributes on ParameterList is not supported.\n",
      "  warnings.warn(\"Setting attributes on ParameterList is not supported.\")\n",
      "  0%|          | 0/36 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "loss: 0.5119 ||: 100%|██████████| 36/36 [00:17<00:00,  2.06it/s]\n",
      "loss: 1.0067 ||: 100%|██████████| 4/4 [00:01<00:00,  2.37it/s]\n"
     ]
    }
   ],
   "source": [
    "metrics = trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:vocabulary serialization directory ../../models/agent-benchmark/elmo-vocabulary is not empty\n"
     ]
    }
   ],
   "source": [
    "# Here's how to save the model.\n",
    "with open(ELMO_MODEL_PATH, 'wb+') as f:\n",
    "    torch.save(model.state_dict(), f)\n",
    "\n",
    "vocab.save_to_files(ELMO_VOCAB_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# And here's how to reload the model.\n",
    "vocab2 = Vocabulary.from_files(ELMO_VOCAB_PATH)\n",
    "\n",
    "model = BaselineModel(\n",
    "    word_embeddings, \n",
    "    encoder, num_labels)\n",
    "\n",
    "with open(ELMO_MODEL_PATH, 'rb') as f:\n",
    "    model.load_state_dict(torch.load(f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "BaselineModel(\n",
       "  (word_embeddings): BasicTextFieldEmbedder(\n",
       "    (token_embedder_tokens): ElmoTokenEmbedder(\n",
       "      (_elmo): Elmo(\n",
       "        (_elmo_lstm): _ElmoBiLm(\n",
       "          (_token_embedder): _ElmoCharacterEncoder(\n",
       "            (char_conv_0): Conv1d(16, 32, kernel_size=(1,), stride=(1,))\n",
       "            (char_conv_1): Conv1d(16, 32, kernel_size=(2,), stride=(1,))\n",
       "            (char_conv_2): Conv1d(16, 64, kernel_size=(3,), stride=(1,))\n",
       "            (char_conv_3): Conv1d(16, 128, kernel_size=(4,), stride=(1,))\n",
       "            (char_conv_4): Conv1d(16, 256, kernel_size=(5,), stride=(1,))\n",
       "            (char_conv_5): Conv1d(16, 512, kernel_size=(6,), stride=(1,))\n",
       "            (char_conv_6): Conv1d(16, 1024, kernel_size=(7,), stride=(1,))\n",
       "            (_highways): Highway(\n",
       "              (_layers): ModuleList(\n",
       "                (0): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "                (1): Linear(in_features=2048, out_features=4096, bias=True)\n",
       "              )\n",
       "            )\n",
       "            (_projection): Linear(in_features=2048, out_features=512, bias=True)\n",
       "          )\n",
       "          (_elmo_lstm): ElmoLstm(\n",
       "            (forward_layer_0): LstmCellWithProjection(\n",
       "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "            )\n",
       "            (backward_layer_0): LstmCellWithProjection(\n",
       "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "            )\n",
       "            (forward_layer_1): LstmCellWithProjection(\n",
       "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "            )\n",
       "            (backward_layer_1): LstmCellWithProjection(\n",
       "              (input_linearity): Linear(in_features=512, out_features=16384, bias=False)\n",
       "              (state_linearity): Linear(in_features=512, out_features=16384, bias=True)\n",
       "              (state_projection): Linear(in_features=4096, out_features=512, bias=False)\n",
       "            )\n",
       "          )\n",
       "        )\n",
       "        (_dropout): Dropout(p=0.5, inplace=False)\n",
       "        (scalar_mix_0): ScalarMix(\n",
       "          (scalar_parameters): ParameterList(\n",
       "              (0): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
       "              (1): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
       "              (2): Parameter containing: [torch.cuda.FloatTensor of size 1 (GPU 1)]\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (encoder): PytorchSeq2VecWrapper(\n",
       "    (_module): LSTM(1024, 300, batch_first=True, bidirectional=True)\n",
       "  )\n",
       "  (projection): Linear(in_features=600, out_features=64, bias=True)\n",
       "  (loss): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.cuda(gpu)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generating Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "from scipy.special import expit # the sigmoid function\n",
    "\n",
    "def tonp(tsr): return tsr.detach().cpu().numpy()\n",
    "\n",
    "class Predictor:\n",
    "    def __init__(self, model: Model, iterator: DataIterator,\n",
    "                 cuda_device: int=-1) -> None:\n",
    "        self.model = model\n",
    "        self.iterator = iterator\n",
    "        self.cuda_device = cuda_device\n",
    "        \n",
    "    def _extract_data(self, batch) -> np.ndarray:\n",
    "        out_dict = self.model(**batch)\n",
    "        return tonp(out_dict[\"class_probabilities\"])\n",
    "    \n",
    "    def predict(self, ds: Iterable[Instance]) -> np.ndarray:\n",
    "        pred_generator = self.iterator(ds, num_epochs=1, shuffle=False)\n",
    "        self.model.eval()\n",
    "        pred_generator_tqdm = tqdm(pred_generator,\n",
    "                                   total=self.iterator.get_num_batches(ds))\n",
    "        preds = []\n",
    "        with torch.no_grad():\n",
    "            for batch in pred_generator_tqdm:\n",
    "                batch = nn_util.move_to_device(batch, self.cuda_device)\n",
    "                preds.append(self._extract_data(batch))\n",
    "        return np.concatenate(preds, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "from allennlp.data.iterators import BasicIterator\n",
    "# iterate over the dataset without changing its order\n",
    "seq_iterator = BasicIterator(batch_size=64)\n",
    "seq_iterator.index_with(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/80 [00:00<?, ?it/s]/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:22: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "100%|██████████| 80/80 [00:09<00:00,  8.59it/s]\n"
     ]
    }
   ],
   "source": [
    "predictor = Predictor(model, seq_iterator, cuda_device=gpu if USE_GPU else -1)\n",
    "test_preds = predictor.predict(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_pred=test_preds.argmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_test = []\n",
    "for x in test_dataset:\n",
    "    Y_test.append(vars(x.fields['label'])['_label_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_dict = model.vocab.get_index_to_token_vocabulary('labels')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'audiobook_play'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_dict[26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.792     0.795     0.793       244\n",
      "           1      0.937     0.972     0.954       214\n",
      "           2      0.661     0.831     0.736       195\n",
      "           3      0.812     0.786     0.799       192\n",
      "           4      0.944     0.859     0.899       177\n",
      "           5      0.733     0.786     0.759       168\n",
      "           6      0.617     0.558     0.586       165\n",
      "           7      0.741     0.705     0.723       146\n",
      "           8      0.855     0.890     0.872       146\n",
      "           9      0.826     0.784     0.804       139\n",
      "          10      0.609     0.741     0.669       139\n",
      "          11      0.765     0.844     0.803       135\n",
      "          12      0.828     0.895     0.860       124\n",
      "          13      0.612     0.582     0.597       122\n",
      "          14      0.453     0.325     0.379       120\n",
      "          15      0.865     0.776     0.818       116\n",
      "          16      0.892     0.853     0.872       116\n",
      "          17      0.718     0.778     0.747       108\n",
      "          18      0.904     0.781     0.838        96\n",
      "          19      0.785     0.768     0.777        95\n",
      "          20      0.752     0.863     0.804        95\n",
      "          21      0.671     0.648     0.659        88\n",
      "          22      0.667     0.675     0.671        83\n",
      "          23      0.819     0.840     0.829        81\n",
      "          24      0.603     0.473     0.530        74\n",
      "          25      0.803     0.875     0.838        56\n",
      "          26      0.865     0.818     0.841        55\n",
      "          27      0.775     0.585     0.667        53\n",
      "          28      0.733     0.647     0.688        51\n",
      "          29      0.485     0.640     0.552        50\n",
      "          30      0.860     0.860     0.860        50\n",
      "          31      0.980     0.980     0.980        50\n",
      "          32      0.577     0.306     0.400        49\n",
      "          33      0.531     0.694     0.602        49\n",
      "          34      0.792     0.875     0.832        48\n",
      "          35      0.957     0.917     0.936        48\n",
      "          36      0.810     0.723     0.764        47\n",
      "          37      0.561     0.804     0.661        46\n",
      "          38      0.635     0.717     0.673        46\n",
      "          39      0.286     0.311     0.298        45\n",
      "          40      0.680     0.756     0.716        45\n",
      "          41      0.629     0.489     0.550        45\n",
      "          42      0.840     0.933     0.884        45\n",
      "          43      0.714     0.682     0.698        44\n",
      "          44      0.597     0.841     0.698        44\n",
      "          45      0.460     0.535     0.495        43\n",
      "          46      0.591     0.302     0.400        43\n",
      "          47      0.667     0.512     0.579        43\n",
      "          48      0.589     0.767     0.667        43\n",
      "          49      0.864     0.884     0.874        43\n",
      "          50      0.660     0.814     0.729        43\n",
      "          51      0.619     0.302     0.406        43\n",
      "          52      0.493     0.810     0.613        42\n",
      "          53      1.000     0.143     0.250        42\n",
      "          54      0.829     0.810     0.819        42\n",
      "          55      0.946     0.854     0.897        41\n",
      "          56      0.897     0.854     0.875        41\n",
      "          57      0.488     0.512     0.500        41\n",
      "          58      0.667     0.650     0.658        40\n",
      "          59      0.795     0.816     0.805        38\n",
      "          60      0.778     0.737     0.757        38\n",
      "          61      0.706     0.649     0.676        37\n",
      "          62      0.704     0.543     0.613        35\n",
      "          63      0.794     0.794     0.794        34\n",
      "\n",
      "    accuracy                          0.740      5116\n",
      "   macro avg      0.727     0.712     0.708      5116\n",
      "weighted avg      0.745     0.740     0.736      5116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "print(classification_report(Y_test, Y_pred, digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
