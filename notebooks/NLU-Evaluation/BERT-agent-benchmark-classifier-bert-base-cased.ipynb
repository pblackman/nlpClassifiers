{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on https://medium.com/swlh/painless-fine-tuning-of-bert-in-pytorch-b91c14912caa\n",
    "https://github.com/aniruddhachoudhury/BERT-Tutorials/blob/master/Blog%202/BERT_Fine_Tuning_Sentence_Classification.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "from os.path import join\n",
    "import torch\n",
    "from nlpClassifiers.data.dataset  import NLPDataset\n",
    "#from torch.optim import AdamW, SGD\n",
    "from torch.utils.data import DataLoader, SequentialSampler, RandomSampler\n",
    "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
    "from transformers import get_linear_schedule_with_warmup\n",
    "from torch.nn import LayerNorm as BertLayerNorm\n",
    "import numpy as np\n",
    "import time\n",
    "import logging\n",
    "import datetime\n",
    "import random\n",
    "import pandas as pd\n",
    "import argparse\n",
    "import pickle as pk\n",
    "import itertools\n",
    "import os\n",
    "import shutil\n",
    "from pathlib import Path\n",
    "import copy\n",
    "import wandb\n",
    "import re\n",
    "from nlpClassifiers import settings\n",
    "from scipy.special import expit\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(\n",
    "    model_path: Path,\n",
    "    dataset: str,\n",
    "    batch_size: int,\n",
    "    labels_dict,\n",
    "    device: torch.device\n",
    "):\n",
    "       \n",
    "    print(f\"====Loading dataset for testing\")\n",
    "    test_corpus = NLPDataset(dataset, \"test\", sentence_max_len, bert_path, labels_dict)\n",
    "    test_dataloader = DataLoader(\n",
    "        test_corpus,\n",
    "        batch_size=batch_size,\n",
    "        #sampler = RandomSampler(test_corpus),\n",
    "        pin_memory=True,\n",
    "        num_workers=0,\n",
    "        drop_last=False\n",
    "    )\n",
    "\n",
    "    print(f\"====Loading model for testing\")\n",
    "    model = BertForSequenceClassification.from_pretrained(\n",
    "        model_path,\n",
    "        num_labels = train_corpus.num_labels,\n",
    "        output_attentions = False,\n",
    "        output_hidden_states = True,\n",
    "    )\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "  #  cm = ConfusionMatrix([0,1])\n",
    "    pred_labels = []\n",
    "    test_labels = []\n",
    "    logits_list = []\n",
    "\n",
    "    def _list_from_tensor(tensor):\n",
    "        if tensor.numel() == 1:\n",
    "            return [tensor.item()]\n",
    "        return list(tensor.cpu().detach().numpy())\n",
    "\n",
    "    print(\"====Testing model...\")\n",
    "    for batch in test_dataloader:\n",
    "        batch = tuple(t.to(device) for t in batch)\n",
    "        b_input_ids, b_segment_ids, b_input_mask, b_labels = batch\n",
    "        with torch.no_grad():\n",
    "            loss, logits, *_ =  model(b_input_ids, b_input_mask, token_type_ids=None, labels=b_labels)\n",
    "\n",
    "            preds = np.argmax(logits.cpu(), axis=1) # Convert one-hot to index\n",
    "            b_labels = b_labels.int()\n",
    "            pred_labels.extend(_list_from_tensor(preds))\n",
    "            test_labels.extend(_list_from_tensor(b_labels))\n",
    "        logits_list.extend(_list_from_tensor(logits))\n",
    "    print(classification_report(test_labels, pred_labels, labels=list(labels_dict.values()), target_names=np.array(list(labels_dict.keys())), digits=3))\n",
    "    logits_list = expit(logits_list)\n",
    "    del model\n",
    "    torch.cuda.empty_cache()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = '../../data/virtual-operator'\n",
    "MODELS_PATH = '../../models/virtual-operator/bert-base-portuguese-tapt-classifier/'\n",
    "PATH_TO_BERT = '../../models/virtual-operator/bertimbau-adaptive-base-finetuned/'\n",
    "TRAIN_DATASET = os.path.join(DATA_PATH, 'train.csv')\n",
    "VAL_DATASET = os.path.join(DATA_PATH, 'val.csv')\n",
    "TEST_DATASET  = os.path.join(DATA_PATH, 'test.csv')\n",
    "PATH_TO_VIRTUAL_OPERATOR_MODELS =  \"../../models/virtual-operator\"\n",
    "PATH_TO_AGENT_BENCHMARK_MODELS = \"../../models/agent-benchmark\"\n",
    "PATH_TO_ML_PT_MODELS = \"../../models/mercado-livre-pt-only\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "gpu = 0\n",
    "dataset = 'agent-benchmark'\n",
    "save_name = 'agent-benchmark-100-epochs-early-stop-reset-3-bert-base-cased'\n",
    "bert_path = 'bert-base-cased'\n",
    "batch_size = 16\n",
    "sentence_max_len = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_PATH_TO_MODELS = {\"virtual-operator\": PATH_TO_VIRTUAL_OPERATOR_MODELS, \"agent-benchmark\": PATH_TO_AGENT_BENCHMARK_MODELS, \"mercado-livre-pt\": PATH_TO_ML_PT_MODELS}\n",
    "FULL_PATH_TO_MODELS = join(BASE_PATH_TO_MODELS[dataset], \"bert-base-portuguese-tapt-classifier\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(f\"cuda:{gpu}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_path = Path(\n",
    "    FULL_PATH_TO_MODELS, \n",
    "    f\"base-dataset-{dataset}-{save_name}\"\n",
    ")\n",
    "last_saved_model = model_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_corpus = NLPDataset(dataset, \"train\", sentence_max_len, bert_path)\n",
    "labels_dict = train_corpus.labels_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "====Loading dataset for testing\n",
      "====Loading model for testing\n",
      "====Testing model...\n",
      "                           precision    recall  f1-score   support\n",
      "\n",
      "    calendar_notification      0.361     0.489     0.415        45\n",
      "     transport_directions      0.760     0.463     0.576        41\n",
      "           cooking_recipe      0.879     0.644     0.744        45\n",
      "               radio_play      0.812     0.842     0.827       139\n",
      "             lists_remove      0.943     0.815     0.874        81\n",
      "               news_query      0.759     0.712     0.735       146\n",
      "         cooking_question      0.556     0.667     0.606        45\n",
      "           contacts_query      0.851     0.755     0.800        53\n",
      "             general_joke      0.913     0.933     0.923        45\n",
      "               audio_mute      0.750     0.789     0.769        38\n",
      "            QA_open_query      0.530     0.442     0.482       120\n",
      "          transport_train      0.786     0.968     0.868        95\n",
      "         weather_question      0.673     0.773     0.720        88\n",
      "           music_question      0.844     0.614     0.711        44\n",
      "               QA_factoid      0.782     0.790     0.786       195\n",
      "              email_query      0.959     0.915     0.936       177\n",
      "              lists_query      0.911     0.863     0.886        95\n",
      "     general_conversation      0.621     0.655     0.637       165\n",
      "recommendation_locations       0.705     0.721     0.713        43\n",
      "       calendar_set_event      0.880     0.839     0.859       192\n",
      "          weather_request      0.789     0.821     0.805       168\n",
      "            QA_definition      0.854     0.895     0.874       124\n",
      "           takeaway_query      0.976     0.851     0.909        47\n",
      "                  IOT_hue      0.968     0.986     0.977       214\n",
      "           datetime_query      0.846     0.852     0.849       135\n",
      "              email_reply      0.971     0.767     0.857        43\n",
      "                 QA_maths      0.750     0.789     0.769        38\n",
      "             lists_adding      0.897     0.765     0.825        34\n",
      "             QA_celebrity      0.892     0.769     0.826       108\n",
      "               music_play      0.739     0.836     0.785       244\n",
      "                game_play      0.857     0.857     0.857        56\n",
      "                 IOT_wemo      0.949     0.902     0.925        41\n",
      "          general_mistake      0.585     0.633     0.608        49\n",
      "           music_settings      0.576     0.680     0.624        50\n",
      "              alarm_query      0.700     0.757     0.727        37\n",
      "    recommendation_movies      0.857     0.419     0.563        43\n",
      "    calendar_delete_event      0.848     0.918     0.882       146\n",
      "             social_query      0.804     0.804     0.804        46\n",
      "           takeaway_order      0.714     0.795     0.753        44\n",
      "        transport_traffic      0.830     0.907     0.867        43\n",
      "           audiobook_play      0.953     0.745     0.837        55\n",
      "         email_send_email      0.872     0.940     0.905       116\n",
      "         general_feedback      0.839     0.748     0.791       139\n",
      "               IOT_coffee      0.907     0.980     0.942        50\n",
      "            podcasts_play      0.974     0.792     0.874        96\n",
      "             alarm_remove      0.871     0.675     0.761        40\n",
      "                alarm_set      0.851     0.833     0.842        48\n",
      "           reminder_query      0.794     0.587     0.675        46\n",
      "              social_post      0.947     0.922     0.934       116\n",
      "           lists_creating      0.783     0.857     0.818        42\n",
      "        datetime_question      0.667     0.651     0.659        43\n",
      "                 QA_stock      0.885     0.920     0.902        50\n",
      "        general_confusion      0.609     0.857     0.712        49\n",
      "        calendar_question      0.763     0.690     0.725        42\n",
      "             audio_volume      0.719     0.804     0.759        51\n",
      "    news_set_notification      0.463     0.595     0.521        42\n",
      "   recommendation_events       0.550     0.767     0.641        43\n",
      "        music_preferences      0.701     0.651     0.675        83\n",
      "             IOT_cleaning      0.978     0.938     0.957        48\n",
      "     general_confirmation      0.472     0.395     0.430        43\n",
      "     calendar_query_event      0.633     0.721     0.674       122\n",
      "           transport_taxi      0.974     0.902     0.937        41\n",
      "             reminder_set      0.528     0.514     0.521        74\n",
      "         datetime_convert      0.703     0.743     0.722        35\n",
      "\n",
      "                 accuracy                          0.789      5116\n",
      "                macro avg      0.783     0.764     0.768      5116\n",
      "             weighted avg      0.796     0.789     0.789      5116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "predict(last_saved_model, dataset, batch_size, labels_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
